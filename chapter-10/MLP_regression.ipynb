{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "888620e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf175f3",
   "metadata": {},
   "source": [
    "Usar a sequential API para usar uma MLP de regressão é bem semelhante ao de classificação. As principais diferenças são que a camada de saída possui apenas um neurônio, não usar função de ativação e função de perda é MSE\n",
    "\n",
    "__Ponto Importante:__ Diferente de visão computacional, dados tabulares não se beneficiam muito de redes profundas. Ou seja, vamos precisar de apenas uma camada oculta. Um baseline simples para seguir também é utilizar de 2x à 4x n_features.\n",
    "\n",
    "Mais neurônios → mais capacidade → mais risco de overfitting\n",
    "\n",
    "Mais camadas → mais complexidade → nem sempre útil em tabular\n",
    "\n",
    "Isso são para MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfe16887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8258 - val_loss: 0.8077\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6265 - val_loss: 0.6886\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4849 - val_loss: 0.4396\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4460 - val_loss: 0.4209\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4308 - val_loss: 0.4086\n",
      "Epoch 6/20\n",
      "\u001b[1m130/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4332"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m model = keras.models.Sequential([\n\u001b[32m      2\u001b[39m     keras.Input(X_train.shape[\u001b[32m1\u001b[39m:]),\n\u001b[32m      3\u001b[39m     keras.layers.Dense(\u001b[32m30\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      4\u001b[39m     keras.layers.Dense(\u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m ])\n\u001b[32m      6\u001b[39m model.compile(loss=\u001b[33m\"\u001b[39m\u001b[33mmean_squared_error\u001b[39m\u001b[33m\"\u001b[39m, optimizer=\u001b[33m\"\u001b[39m\u001b[33msgd\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m mse_test = model.evaluate(X_test, y_test)\n\u001b[32m     11\u001b[39m X_new = X_test[:\u001b[32m3\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:242\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m     iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m ):\n\u001b[32m    241\u001b[39m     opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    243\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\optional_ops.py:176\u001b[39m, in \u001b[36m_OptionalImpl.has_value\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_optional_ops.py:172\u001b[39m, in \u001b[36moptional_has_value\u001b[39m\u001b[34m(optional, name)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m    171\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOptionalHasValue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.Input(X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9d75f",
   "metadata": {},
   "source": [
    "# Usando functional API para construir modelos complexos\n",
    "\n",
    "utilizaremos o modelo _Wide & Deep_, que interliga todas ou parte das entradas diretamente à camada de saída. Essa arquitetura possibilita à rede neural aprender padrões profundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1d1af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b236570",
   "metadata": {},
   "source": [
    "Explicando cada linha acima:\n",
    "\n",
    "- Primeiro é necessario criar um objeto _Input()_, onde especifica o tipo de entrada que o modelo obterá, com shape e dtype\n",
    "- Criamos uma camada oculta Dense com 30 neurônios, nós a chamamos como uma função passando a entrada. Estamos apenas informando à Keras como ele deve conectar as camadas, com nenhum dado real sendo processado ainda\n",
    "- Criamos outra camada oculta, e de novo usamos como função. Passamos para a saída da primeira camada oculta.\n",
    "- Criamos uma camada _Concatenate()_ e mais uma vez usamos como função para concatenar a entrada e saída da segunda camada oculta.\n",
    "- Criamos uma camada de saída com um único neurônio e sem função de ativação, chamamos novamente como função e passamos pelo resultado da concatenação\n",
    "- Criamos o modelo dizendo quais entradas e saídas utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f94436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22676ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.0255 - val_loss: 0.6464\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4971 - val_loss: 0.5076\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4439 - val_loss: 0.4489\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4001 - val_loss: 0.4284\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3750 - val_loss: 0.4071\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3664 - val_loss: 0.4040\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3563 - val_loss: 0.3935\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3465 - val_loss: 0.3956\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3543 - val_loss: 0.3879\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3382 - val_loss: 0.3719\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3299 - val_loss: 0.3764\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3307 - val_loss: 0.3710\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3179 - val_loss: 0.3740\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3175 - val_loss: 0.3698\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3246 - val_loss: 0.3552\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3131 - val_loss: 0.3562\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3121 - val_loss: 0.3504\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3091 - val_loss: 0.3647\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3009 - val_loss: 0.3512\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3014 - val_loss: 0.3521\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "e_stop = EarlyStopping(\n",
    "    monitor ='val_loss',\n",
    "    patience = 3,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=e_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5f2d984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) #precisa definir o intervalo vertical para 0 até 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8c874e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3226\n"
     ]
    }
   ],
   "source": [
    "mse_test_adam = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f4e0a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.56613016],\n",
       "       [1.3953164 ],\n",
       "       [4.210506  ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8684d",
   "metadata": {},
   "source": [
    "Caso queira enviar um subconjunto de características pelo caminho amplo e um subconjunto diferente pelo caminho profundo, devemos utilizar diversas entradas.\n",
    "\n",
    "Por exemplo: desejo enviar cinco características pelo caminho amplo (de 0 a 4), e seis pelo caminho profundo (2 a 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94a9eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B) #lidamos com camadas ocultas apenas no deep input\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2]) #concatenamos tudo antes da output layer\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4950d72",
   "metadata": {},
   "source": [
    "Especificamos os inputs ao criar o modelo, porém agora para chamar o método _fit()_, precisamos passar um par de matriz X_train_A e X_train_B. Como alterantiva podemos passar um dicionário mapeando os nomes de entrada:\n",
    "\n",
    "{'wide_input': X_train_A, 'deep_input', X_train_B} -> ajuda bastante quando temos muitas entradas para evitar erro no ordenamento.\n",
    "\n",
    "O mesmo vale para X_val, X_test e X_new para quando chamarmos o _evaluate()_ ou _predict()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c5e3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_val_A, X_val_B = X_val[:, :5], X_val[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "X_train_dic = {\n",
    "    'wide_input': X_train_A,\n",
    "    'deep_input': X_train_B\n",
    "}\n",
    "\n",
    "X_val_dic = {\n",
    "    'wide_input': X_val_A,\n",
    "    'deep_input': X_val_B\n",
    "}\n",
    "\n",
    "X_test_dic = {\n",
    "    'wide_input': X_test_A,\n",
    "    'deep_input': X_test_B\n",
    "}\n",
    "\n",
    "X_new_dic = {\n",
    "    'wide_input': X_new_A,\n",
    "    'deep_input': X_new_B\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29dc2f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.4063 - val_loss: 0.6303\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5205 - val_loss: 0.4516\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4364 - val_loss: 0.4204\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4175 - val_loss: 0.4104\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4047 - val_loss: 0.3952\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3911 - val_loss: 0.3996\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3864 - val_loss: 0.3799\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3882 - val_loss: 0.3686\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3638 - val_loss: 0.3634\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3685 - val_loss: 0.3679\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3552 - val_loss: 0.3536\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3483 - val_loss: 0.3559\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3464 - val_loss: 0.3547\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3512 - val_loss: 0.3473\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3333 - val_loss: 0.3405\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3359 - val_loss: 0.3486\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3328 - val_loss: 0.3372\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3286 - val_loss: 0.3661\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3260 - val_loss: 0.3366\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3317 - val_loss: 0.3434\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_dic, y_train, epochs=20, validation_data=(X_val_dic, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b0d27f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3360\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000015A896F5E40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000015A896F5E40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_dic, y_test)\n",
    "\n",
    "y_pred = model.predict(X_new_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f4ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5693517195279238)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "RMSE = np.sqrt(mse_test)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fba1b6",
   "metadata": {},
   "source": [
    "Alguns casos de uso:\n",
    "\n",
    "- Podemos localizar e classificar o objeto principal de uma imagem, isso é uma tarefa de regressão (identificar as coordenadas do centro do objeto, largura e altura) e uma tarefa de classificação\n",
    "- Podemos ter diversas tarefas independentes com base nos mesmos dados, podemos treinar uma rede neural por tarefa, mas obtemos melhores resultados em todas as tarefas treinando uma única rede neural com uma saída por tarefa\n",
    "- Podemos utilizar saídas auxiliares para fazer o modelo aprender algo útil sozinha sem depender do restante da rede, sendo isso uma técnica de regularização com objetivo de reduzir overfitting e melhorar a capacidade de generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b57abc2",
   "metadata": {},
   "source": [
    "# subclassing API para construir modelos dinâmicos\n",
    "\n",
    "A subclassing API do Keras é útil principalmente quando o problema exige um nível de flexibilidade que as abordagens declarativas (Sequential e Functional) não conseguem oferecer bem.\n",
    "\n",
    "Nas APIs tradicionais, você define a arquitetura de forma estática: primeiro declara todas as camadas e como elas se conectam, e só depois passa os dados. Isso traz vantagens como facilidade de visualização, validação automática e menor chance de erro estrutural. No entanto, esse modelo é limitado quando precisamos de comportamentos mais dinâmicos, como loops, condicionais, múltiplos fluxos com lógica customizada ou arquiteturas que mudam dependendo da entrada.\n",
    "\n",
    "É nesse ponto que a subclassing API se destaca. Ao herdar de keras.Model, você passa a construir o modelo de forma imperativa, definindo as camadas no __init__ e controlando explicitamente o fluxo de dados no método call(). Isso permite implementar lógicas mais complexas, como ramificações condicionais, múltiplas saídas com tratamentos diferentes (como no exemplo com main_output e aux_output) e estruturas que não podem ser facilmente representadas como um grafo estático.\n",
    "\n",
    "Por outro lado, essa flexibilidade tem um custo. O modelo deixa de ser totalmente transparente: sua arquitetura não é tão facilmente inspecionável, não pode ser salva ou clonada com a mesma simplicidade e há menos validações automáticas por parte do Keras. Isso aumenta a responsabilidade do desenvolvedor e a chance de erros.\n",
    "\n",
    "Em resumo, a subclassing API é ideal quando você precisa de controle total sobre o comportamento do modelo, especialmente em cenários mais avançados ou de pesquisa. Porém, para problemas mais simples e estruturados, as APIs declarativas continuam sendo mais seguras, rápidas e fáceis de manter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f01dd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        \n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        \n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        \n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        \n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452f183",
   "metadata": {},
   "source": [
    "# Salvando e armazenando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6be23aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/keras_model_wide_deep.keras') # salvei o modelo utilizado anteriormente, a classe acima precisaria se compilada e treinada para então poder salvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para carregar o modelo é tão simples quanto:\n",
    "model = keras.models.load_model('models/keras_model_wide_deep.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f985d596",
   "metadata": {},
   "source": [
    "Caso tenhamos muitos e muitos dados, salvar o modelo apenas no fim do treinamento é algo ruim. Utilizamos checkpoints durante o treinamento para evitar perder tudo\n",
    "\n",
    "# Usando funções de callbacks\n",
    "O Keras chama os callbacks no início e fim de cada treinamento, época e antes e depois do processamento de cada batch. _ModelCheckpoint()_ salva os checkpoints do modelo em intervalos regulares durante o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Após a contrução e compilação do modelo utilizamos o seguinte código:\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('models/keras_model_wide_deep.keras', monitor='val_loss', save_best_only=True) # fazemos com que o checkpoimt salve o modelo quando  conjunto de validação for o melhor\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[checkpoint])\n",
    "model = keras.models.load_model('models/keras_model_wide_deep.keras') # reverte para o melhor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e4dee",
   "metadata": {},
   "source": [
    "# TensorBoard para visualização\n",
    "Ferramenta para visualização de curvas de treinamento durante o aprendizado, podemos usa para comparar com as diversas execuções, visualizar o grafo computacional, as imagens geradas pelo modelo, dados multidimensionais, estatísticas de treinamento e muito mais.\n",
    "\n",
    "Para utilizar, devemos fazer com que o programa gere a saída dos dados em log binários chamados _event files_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f73c2eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2912 - val_loss: 0.3201\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2889 - val_loss: 0.3014\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2925 - val_loss: 0.3231\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2879 - val_loss: 0.3024\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2875 - val_loss: 0.3365\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2869 - val_loss: 0.3005\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2868 - val_loss: 0.3019\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2854 - val_loss: 0.3114\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2862 - val_loss: 0.3027\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2834 - val_loss: 0.3157\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2869 - val_loss: 0.3152\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2863 - val_loss: 0.3012\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2815 - val_loss: 0.2980\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2818 - val_loss: 0.2969\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2809 - val_loss: 0.3003\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2823 - val_loss: 0.2922\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2807 - val_loss: 0.2904\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2799 - val_loss: 0.2991\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2787 - val_loss: 0.3036\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2808 - val_loss: 0.2950\n"
     ]
    }
   ],
   "source": [
    "# Keras oferece uma callback chamada TensorBoard()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train_dic, y_train, epochs=20, validation_data=(X_val_dic, y_val), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d4e75",
   "metadata": {},
   "source": [
    "# Aperfeiçoando os hiperparâmetros das redes neurais\n",
    "Podemos utilizar o _GridSearchCV_ e o _RandomizedSearchCV_ para explorar o espaço do hiperparâmetro, mas para isso precisamos criar uma função que construirá e compilará um modelo Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c838a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape_=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(shape=input_shape_))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer_ = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer= optimizer_)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construiremos um KerasRegressor com base na função acima, porém conforme o livro tem uma função desatualizada, precisamos instalar o scikeras\n",
    "# pip install scikeras[tensorflow]\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "keras_reg = KerasRegressor(model=build_model, input_shape_=[X_train.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909596a",
   "metadata": {},
   "source": [
    "_KerasRegressor_ é um pequeno wrapper em torno do modelo Keras, onde podemos usar como um regressor da SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5b7380a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4776 - val_loss: 0.5019\n",
      "Epoch 2/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4454 - val_loss: 0.3918\n",
      "Epoch 3/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4075 - val_loss: 0.3932\n",
      "Epoch 4/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3967 - val_loss: 0.4045\n",
      "Epoch 5/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3875 - val_loss: 0.3760\n",
      "Epoch 6/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3764 - val_loss: 0.3826\n",
      "Epoch 7/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3754 - val_loss: 0.3757\n",
      "Epoch 8/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3637 - val_loss: 0.3492\n",
      "Epoch 9/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3520 - val_loss: 0.3990\n",
      "Epoch 10/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3486 - val_loss: 0.3792\n",
      "Epoch 11/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3529 - val_loss: 0.3812\n",
      "Epoch 12/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3421 - val_loss: 0.4124\n",
      "Epoch 13/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3419 - val_loss: 0.3241\n",
      "Epoch 14/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3356 - val_loss: 0.3723\n",
      "Epoch 15/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3441 - val_loss: 0.3288\n",
      "Epoch 16/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3303 - val_loss: 0.3294\n",
      "Epoch 17/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3292 - val_loss: 0.3310\n",
      "Epoch 18/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3267 - val_loss: 0.3362\n",
      "Epoch 19/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3263 - val_loss: 0.3251\n",
      "Epoch 20/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3269 - val_loss: 0.3443\n",
      "Epoch 21/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3238 - val_loss: 0.3698\n",
      "Epoch 22/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3215 - val_loss: 0.3220\n",
      "Epoch 23/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3288 - val_loss: 0.3396\n",
      "Epoch 24/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3254 - val_loss: 0.3481\n",
      "Epoch 25/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3215 - val_loss: 0.3251\n",
      "Epoch 26/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3162 - val_loss: 0.3299\n",
      "Epoch 27/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3192 - val_loss: 0.3117\n",
      "Epoch 28/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3178 - val_loss: 0.3402\n",
      "Epoch 29/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3153 - val_loss: 0.3711\n",
      "Epoch 30/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3168 - val_loss: 0.3162\n",
      "Epoch 31/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3167 - val_loss: 0.3166\n",
      "Epoch 32/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3133 - val_loss: 0.3404\n",
      "Epoch 33/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3189 - val_loss: 0.3561\n",
      "Epoch 34/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3192 - val_loss: 0.3190\n",
      "Epoch 35/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3152 - val_loss: 0.3159\n",
      "Epoch 36/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3161 - val_loss: 0.3076\n",
      "Epoch 37/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3111 - val_loss: 0.3118\n",
      "Epoch 38/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3139 - val_loss: 0.3457\n",
      "Epoch 39/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3146 - val_loss: 0.3093\n",
      "Epoch 40/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3095 - val_loss: 0.3233\n",
      "Epoch 41/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3104 - val_loss: 0.3208\n",
      "Epoch 42/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3070 - val_loss: 0.3110\n",
      "Epoch 43/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3089 - val_loss: 0.3224\n",
      "Epoch 44/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3078 - val_loss: 0.3683\n",
      "Epoch 45/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3112 - val_loss: 0.3149\n",
      "Epoch 46/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3059 - val_loss: 0.3588\n",
      "Epoch 47/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3044 - val_loss: 0.3186\n",
      "Epoch 48/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3062 - val_loss: 0.3161\n",
      "Epoch 49/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3014 - val_loss: 0.3164\n",
      "Epoch 50/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3025 - val_loss: 0.3108\n",
      "Epoch 51/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3042 - val_loss: 0.3885\n",
      "Epoch 52/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3106 - val_loss: 0.4050\n",
      "Epoch 53/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3076 - val_loss: 0.3606\n",
      "Epoch 54/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2994 - val_loss: 0.3530\n",
      "Epoch 55/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2996 - val_loss: 0.3184\n",
      "Epoch 56/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2955 - val_loss: 0.3008\n",
      "Epoch 57/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2985 - val_loss: 0.3380\n",
      "Epoch 58/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2980 - val_loss: 0.3306\n",
      "Epoch 59/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3003 - val_loss: 0.3015\n",
      "Epoch 60/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2935 - val_loss: 0.3700\n",
      "Epoch 61/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3061 - val_loss: 0.3054\n",
      "Epoch 62/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2953 - val_loss: 0.2949\n",
      "Epoch 63/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2937 - val_loss: 0.2977\n",
      "Epoch 64/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2949 - val_loss: 0.3086\n",
      "Epoch 65/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2959 - val_loss: 0.3224\n",
      "Epoch 66/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2979 - val_loss: 0.3029\n",
      "Epoch 67/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2957 - val_loss: 0.2935\n",
      "Epoch 68/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2914 - val_loss: 0.3018\n",
      "Epoch 69/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2945 - val_loss: 0.3130\n",
      "Epoch 70/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2920 - val_loss: 0.3079\n",
      "Epoch 71/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2937 - val_loss: 0.3639\n",
      "Epoch 72/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3004 - val_loss: 0.3175\n",
      "Epoch 73/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2916 - val_loss: 0.3275\n",
      "Epoch 74/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2939 - val_loss: 0.3894\n",
      "Epoch 75/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2977 - val_loss: 0.3060\n",
      "Epoch 76/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2899 - val_loss: 0.3060\n",
      "Epoch 77/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2891 - val_loss: 0.3225\n",
      "Epoch 78/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2916 - val_loss: 0.3479\n",
      "Epoch 79/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2903 - val_loss: 0.3215\n",
      "Epoch 80/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2885 - val_loss: 0.2995\n",
      "Epoch 81/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2889 - val_loss: 0.3107\n",
      "Epoch 82/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2891 - val_loss: 0.2953\n",
      "Epoch 83/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2903 - val_loss: 0.3168\n",
      "Epoch 84/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2950 - val_loss: 0.3145\n",
      "Epoch 85/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2920 - val_loss: 0.3056\n",
      "Epoch 86/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2894 - val_loss: 0.3050\n",
      "Epoch 87/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2888 - val_loss: 0.3149\n",
      "Epoch 88/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2926 - val_loss: 0.3295\n",
      "Epoch 89/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2894 - val_loss: 0.3171\n",
      "Epoch 90/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2902 - val_loss: 0.3053\n",
      "Epoch 91/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2880 - val_loss: 0.3108\n",
      "Epoch 92/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2886 - val_loss: 0.3504\n",
      "Epoch 93/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2926 - val_loss: 0.3122\n",
      "Epoch 94/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2887 - val_loss: 0.3167\n",
      "Epoch 95/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2904 - val_loss: 0.3002\n",
      "Epoch 96/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2874 - val_loss: 0.3020\n",
      "Epoch 97/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2897 - val_loss: 0.3225\n",
      "Epoch 98/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2894 - val_loss: 0.3479\n",
      "Epoch 99/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2896 - val_loss: 0.3206\n",
      "Epoch 100/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2864 - val_loss: 0.3240\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b19780",
   "metadata": {},
   "source": [
    "Quando queremos treinar centenas de variantes e ver qual delas apresenta um melhor desempenho, é preferível utilizar _RandomizedSearchCV()_ em vez do _GridSearchCV()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6fcf2749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.0163 - val_loss: 6.7807\n",
      "Epoch 2/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.5146 - val_loss: 6.2620\n",
      "Epoch 3/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0712 - val_loss: 5.8003\n",
      "Epoch 4/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6773 - val_loss: 5.3884\n",
      "Epoch 5/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3204 - val_loss: 5.0109\n",
      "Epoch 6/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9941 - val_loss: 4.6580\n",
      "Epoch 7/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6969 - val_loss: 4.3368\n",
      "Epoch 8/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4212 - val_loss: 4.0401\n",
      "Epoch 9/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.1672 - val_loss: 3.7598\n",
      "Epoch 10/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.9316 - val_loss: 3.5147\n",
      "Epoch 11/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7129 - val_loss: 3.2589\n",
      "Epoch 12/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5099 - val_loss: 3.0377\n",
      "Epoch 13/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3211 - val_loss: 2.8283\n",
      "Epoch 14/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1459 - val_loss: 2.6346\n",
      "Epoch 15/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9833 - val_loss: 2.4512\n",
      "Epoch 16/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8321 - val_loss: 2.2829\n",
      "Epoch 17/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6932 - val_loss: 2.1282\n",
      "Epoch 18/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5648 - val_loss: 1.9821\n",
      "Epoch 19/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4467 - val_loss: 1.8474\n",
      "Epoch 20/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3381 - val_loss: 1.7226\n",
      "Epoch 21/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2394 - val_loss: 1.6140\n",
      "Epoch 22/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1496 - val_loss: 1.5079\n",
      "Epoch 23/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0686 - val_loss: 1.4084\n",
      "Epoch 24/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9959 - val_loss: 1.3206\n",
      "Epoch 25/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9311 - val_loss: 1.2484\n",
      "Epoch 26/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8739 - val_loss: 1.1711\n",
      "Epoch 27/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8238 - val_loss: 1.1058\n",
      "Epoch 28/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7802 - val_loss: 1.0483\n",
      "Epoch 29/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7428 - val_loss: 0.9979\n",
      "Epoch 30/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7114 - val_loss: 0.9532\n",
      "Epoch 31/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6843 - val_loss: 0.9128\n",
      "Epoch 32/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6618 - val_loss: 0.8776\n",
      "Epoch 33/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6434 - val_loss: 0.8456\n",
      "Epoch 34/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6282 - val_loss: 0.8180\n",
      "Epoch 35/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6159 - val_loss: 0.7932\n",
      "Epoch 36/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6060 - val_loss: 0.7699\n",
      "Epoch 37/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5979 - val_loss: 0.7501\n",
      "Epoch 38/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5911 - val_loss: 0.7310\n",
      "Epoch 39/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5852 - val_loss: 0.7130\n",
      "Epoch 40/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5801 - val_loss: 0.6955\n",
      "Epoch 41/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5756 - val_loss: 0.6791\n",
      "Epoch 42/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5714 - val_loss: 0.6639\n",
      "Epoch 43/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5677 - val_loss: 0.6498\n",
      "Epoch 44/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5642 - val_loss: 0.6362\n",
      "Epoch 45/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5610 - val_loss: 0.6236\n",
      "Epoch 46/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5579 - val_loss: 0.6115\n",
      "Epoch 47/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5550 - val_loss: 0.6003\n",
      "Epoch 48/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5524 - val_loss: 0.5893\n",
      "Epoch 49/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5500 - val_loss: 0.5793\n",
      "Epoch 50/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5477 - val_loss: 0.5696\n",
      "Epoch 51/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5455 - val_loss: 0.5610\n",
      "Epoch 52/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5435 - val_loss: 0.5532\n",
      "Epoch 53/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5416 - val_loss: 0.5449\n",
      "Epoch 54/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5400 - val_loss: 0.5384\n",
      "Epoch 55/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5385 - val_loss: 0.5331\n",
      "Epoch 56/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5372 - val_loss: 0.5274\n",
      "Epoch 57/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5360 - val_loss: 0.5225\n",
      "Epoch 58/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5350 - val_loss: 0.5181\n",
      "Epoch 59/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5341 - val_loss: 0.5148\n",
      "Epoch 60/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5333 - val_loss: 0.5116\n",
      "Epoch 61/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5328 - val_loss: 0.5087\n",
      "Epoch 62/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5321 - val_loss: 0.5066\n",
      "Epoch 63/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5316 - val_loss: 0.5049\n",
      "Epoch 64/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5314 - val_loss: 0.5039\n",
      "Epoch 65/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5311 - val_loss: 0.5030\n",
      "Epoch 66/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5310 - val_loss: 0.5023\n",
      "Epoch 67/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5023\n",
      "Epoch 68/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5020\n",
      "Epoch 69/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5307 - val_loss: 0.5018\n",
      "Epoch 70/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5308 - val_loss: 0.5016\n",
      "Epoch 71/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5014\n",
      "Epoch 72/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5013\n",
      "Epoch 73/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5013\n",
      "Epoch 74/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5305 - val_loss: 0.5013\n",
      "Epoch 75/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5306 - val_loss: 0.5013\n",
      "Epoch 76/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5305 - val_loss: 0.5011\n",
      "Epoch 77/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5305 - val_loss: 0.5013\n",
      "Epoch 78/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5305 - val_loss: 0.5014\n",
      "Epoch 79/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5305 - val_loss: 0.5013\n",
      "Epoch 80/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5305 - val_loss: 0.5013\n",
      "Epoch 81/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5014\n",
      "Epoch 82/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5012\n",
      "Epoch 83/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5304 - val_loss: 0.5013\n",
      "Epoch 84/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5305 - val_loss: 0.5013\n",
      "Epoch 85/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5012\n",
      "Epoch 86/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5012\n",
      "Epoch 87/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5012\n",
      "Epoch 88/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5010\n",
      "Epoch 89/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5011\n",
      "Epoch 90/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5305 - val_loss: 0.5012\n",
      "Epoch 91/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5304 - val_loss: 0.5015\n",
      "Epoch 92/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5016\n",
      "Epoch 93/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5303 - val_loss: 0.5013\n",
      "Epoch 94/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5303 - val_loss: 0.5014\n",
      "Epoch 95/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5014\n",
      "Epoch 96/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5303 - val_loss: 0.5014\n",
      "Epoch 97/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5013\n",
      "Epoch 98/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5013\n",
      "Epoch 99/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5302 - val_loss: 0.5013\n",
      "Epoch 100/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5303 - val_loss: 0.5017\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.4842 - val_loss: 8.0039\n",
      "Epoch 2/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.8548 - val_loss: 7.3252\n",
      "Epoch 3/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.2795 - val_loss: 6.7110\n",
      "Epoch 4/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.7506 - val_loss: 6.1469\n",
      "Epoch 5/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.2669 - val_loss: 5.6402\n",
      "Epoch 6/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.8232 - val_loss: 5.1751\n",
      "Epoch 7/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.4158 - val_loss: 4.7502\n",
      "Epoch 8/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0428 - val_loss: 4.3628\n",
      "Epoch 9/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7014 - val_loss: 4.0088\n",
      "Epoch 10/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.3881 - val_loss: 3.6857\n",
      "Epoch 11/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.1014 - val_loss: 3.3927\n",
      "Epoch 12/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.8393 - val_loss: 3.1220\n",
      "Epoch 13/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.5996 - val_loss: 2.8758\n",
      "Epoch 14/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3806 - val_loss: 2.6490\n",
      "Epoch 15/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1801 - val_loss: 2.4429\n",
      "Epoch 16/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.9975 - val_loss: 2.2546\n",
      "Epoch 17/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8314 - val_loss: 2.0823\n",
      "Epoch 18/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6804 - val_loss: 1.9238\n",
      "Epoch 19/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5439 - val_loss: 1.7815\n",
      "Epoch 20/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4204 - val_loss: 1.6506\n",
      "Epoch 21/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3094 - val_loss: 1.5329\n",
      "Epoch 22/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2097 - val_loss: 1.4266\n",
      "Epoch 23/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1206 - val_loss: 1.3300\n",
      "Epoch 24/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0412 - val_loss: 1.2419\n",
      "Epoch 25/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9713 - val_loss: 1.1615\n",
      "Epoch 26/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9094 - val_loss: 1.1010\n",
      "Epoch 27/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8555 - val_loss: 1.0274\n",
      "Epoch 28/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8089 - val_loss: 0.9802\n",
      "Epoch 29/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7691 - val_loss: 0.9229\n",
      "Epoch 30/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7347 - val_loss: 0.8790\n",
      "Epoch 31/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7058 - val_loss: 0.8410\n",
      "Epoch 32/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6815 - val_loss: 0.8071\n",
      "Epoch 33/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6613 - val_loss: 0.7781\n",
      "Epoch 34/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6445 - val_loss: 0.7528\n",
      "Epoch 35/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6307 - val_loss: 0.7273\n",
      "Epoch 36/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6192 - val_loss: 0.7059\n",
      "Epoch 37/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6096 - val_loss: 0.6931\n",
      "Epoch 38/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6020 - val_loss: 0.6687\n",
      "Epoch 39/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5948 - val_loss: 0.6527\n",
      "Epoch 40/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5888 - val_loss: 0.6379\n",
      "Epoch 41/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5835 - val_loss: 0.6243\n",
      "Epoch 42/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5786 - val_loss: 0.6117\n",
      "Epoch 43/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5742 - val_loss: 0.5984\n",
      "Epoch 44/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5701 - val_loss: 0.5869\n",
      "Epoch 45/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5664 - val_loss: 0.5763\n",
      "Epoch 46/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5630 - val_loss: 0.5664\n",
      "Epoch 47/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5598 - val_loss: 0.5574\n",
      "Epoch 48/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5568 - val_loss: 0.5487\n",
      "Epoch 49/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5542 - val_loss: 0.5413\n",
      "Epoch 50/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5517 - val_loss: 0.5343\n",
      "Epoch 51/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5495 - val_loss: 0.5282\n",
      "Epoch 52/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5474 - val_loss: 0.5229\n",
      "Epoch 53/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5456 - val_loss: 0.5179\n",
      "Epoch 54/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5439 - val_loss: 0.5141\n",
      "Epoch 55/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5424 - val_loss: 0.5111\n",
      "Epoch 56/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5412 - val_loss: 0.5089\n",
      "Epoch 57/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5401 - val_loss: 0.5071\n",
      "Epoch 58/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5391 - val_loss: 0.5057\n",
      "Epoch 59/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5382 - val_loss: 0.5047\n",
      "Epoch 60/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5374 - val_loss: 0.5040\n",
      "Epoch 61/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5367 - val_loss: 0.5038\n",
      "Epoch 62/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5362 - val_loss: 0.5031\n",
      "Epoch 63/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5356 - val_loss: 0.5030\n",
      "Epoch 64/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5351 - val_loss: 0.5027\n",
      "Epoch 65/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5346 - val_loss: 0.5025\n",
      "Epoch 66/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5341 - val_loss: 0.5022\n",
      "Epoch 67/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5338 - val_loss: 0.5022\n",
      "Epoch 68/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5335 - val_loss: 0.5021\n",
      "Epoch 69/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5332 - val_loss: 0.5020\n",
      "Epoch 70/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5328 - val_loss: 0.5021\n",
      "Epoch 71/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5325 - val_loss: 0.5016\n",
      "Epoch 72/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5322 - val_loss: 0.5016\n",
      "Epoch 73/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5320 - val_loss: 0.5017\n",
      "Epoch 74/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5318 - val_loss: 0.5016\n",
      "Epoch 75/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5316 - val_loss: 0.5013\n",
      "Epoch 76/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5314 - val_loss: 0.5016\n",
      "Epoch 77/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5312 - val_loss: 0.5017\n",
      "Epoch 78/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5014\n",
      "Epoch 79/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5012\n",
      "Epoch 80/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5013\n",
      "Epoch 81/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5305 - val_loss: 0.5014\n",
      "Epoch 82/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5014\n",
      "Epoch 83/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5303 - val_loss: 0.5014\n",
      "Epoch 84/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5303 - val_loss: 0.5018\n",
      "Epoch 85/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5302 - val_loss: 0.5014\n",
      "Epoch 86/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5300 - val_loss: 0.5016\n",
      "Epoch 87/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5300 - val_loss: 0.5014\n",
      "Epoch 88/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5298 - val_loss: 0.5015\n",
      "Epoch 89/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5299 - val_loss: 0.5014\n",
      "Epoch 90/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5298 - val_loss: 0.5016\n",
      "Epoch 91/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5297 - val_loss: 0.5017\n",
      "Epoch 92/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5296 - val_loss: 0.5016\n",
      "Epoch 93/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5295 - val_loss: 0.5020\n",
      "Epoch 94/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5295 - val_loss: 0.5020\n",
      "Epoch 95/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5294 - val_loss: 0.5018\n",
      "Epoch 96/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5294 - val_loss: 0.5018\n",
      "Epoch 97/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5294 - val_loss: 0.5017\n",
      "Epoch 98/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5293 - val_loss: 0.5018\n",
      "Epoch 99/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5292 - val_loss: 0.5019\n",
      "Epoch 100/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5292 - val_loss: 0.5017\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.7825 - val_loss: 9.6915\n",
      "Epoch 2/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.9249 - val_loss: 8.7918\n",
      "Epoch 3/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.1616 - val_loss: 7.9628\n",
      "Epoch 4/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.4717 - val_loss: 7.2190\n",
      "Epoch 5/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.8531 - val_loss: 6.5564\n",
      "Epoch 6/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3016 - val_loss: 5.9473\n",
      "Epoch 7/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8047 - val_loss: 5.3975\n",
      "Epoch 8/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3596 - val_loss: 4.9113\n",
      "Epoch 9/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.9608 - val_loss: 4.4633\n",
      "Epoch 10/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6014 - val_loss: 4.0639\n",
      "Epoch 11/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2782 - val_loss: 3.6974\n",
      "Epoch 12/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.9870 - val_loss: 3.3638\n",
      "Epoch 13/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7245 - val_loss: 3.0738\n",
      "Epoch 14/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.4868 - val_loss: 2.7951\n",
      "Epoch 15/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2726 - val_loss: 2.5438\n",
      "Epoch 16/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0780 - val_loss: 2.3178\n",
      "Epoch 17/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9018 - val_loss: 2.1104\n",
      "Epoch 18/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7419 - val_loss: 1.9254\n",
      "Epoch 19/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5977 - val_loss: 1.7533\n",
      "Epoch 20/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4676 - val_loss: 1.6041\n",
      "Epoch 21/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3503 - val_loss: 1.4642\n",
      "Epoch 22/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2453 - val_loss: 1.3368\n",
      "Epoch 23/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1518 - val_loss: 1.2264\n",
      "Epoch 24/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0683 - val_loss: 1.1314\n",
      "Epoch 25/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9942 - val_loss: 1.0383\n",
      "Epoch 26/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9289 - val_loss: 0.9622\n",
      "Epoch 27/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8720 - val_loss: 0.8914\n",
      "Epoch 28/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8229 - val_loss: 0.8322\n",
      "Epoch 29/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7805 - val_loss: 0.7819\n",
      "Epoch 30/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7445 - val_loss: 0.7390\n",
      "Epoch 31/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7142 - val_loss: 0.7023\n",
      "Epoch 32/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6892 - val_loss: 0.6722\n",
      "Epoch 33/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6684 - val_loss: 0.6472\n",
      "Epoch 34/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6516 - val_loss: 0.6269\n",
      "Epoch 35/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6377 - val_loss: 0.6104\n",
      "Epoch 36/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6267 - val_loss: 0.5975\n",
      "Epoch 37/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6175 - val_loss: 0.5877\n",
      "Epoch 38/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6101 - val_loss: 0.5787\n",
      "Epoch 39/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6037 - val_loss: 0.5718\n",
      "Epoch 40/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5983 - val_loss: 0.5665\n",
      "Epoch 41/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5935 - val_loss: 0.5618\n",
      "Epoch 42/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5891 - val_loss: 0.5577\n",
      "Epoch 43/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5851 - val_loss: 0.5539\n",
      "Epoch 44/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5812 - val_loss: 0.5505\n",
      "Epoch 45/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5775 - val_loss: 0.5472\n",
      "Epoch 46/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5740 - val_loss: 0.5439\n",
      "Epoch 47/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5705 - val_loss: 0.5407\n",
      "Epoch 48/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5672 - val_loss: 0.5379\n",
      "Epoch 49/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5640 - val_loss: 0.5350\n",
      "Epoch 50/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5609 - val_loss: 0.5318\n",
      "Epoch 51/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5580 - val_loss: 0.5309\n",
      "Epoch 52/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5551 - val_loss: 0.5268\n",
      "Epoch 53/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5525 - val_loss: 0.5245\n",
      "Epoch 54/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5501 - val_loss: 0.5225\n",
      "Epoch 55/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5479 - val_loss: 0.5204\n",
      "Epoch 56/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5459 - val_loss: 0.5186\n",
      "Epoch 57/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5440 - val_loss: 0.5174\n",
      "Epoch 58/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5422 - val_loss: 0.5153\n",
      "Epoch 59/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5406 - val_loss: 0.5140\n",
      "Epoch 60/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5392 - val_loss: 0.5130\n",
      "Epoch 61/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5378 - val_loss: 0.5117\n",
      "Epoch 62/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5366 - val_loss: 0.5108\n",
      "Epoch 63/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5355 - val_loss: 0.5099\n",
      "Epoch 64/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5345 - val_loss: 0.5096\n",
      "Epoch 65/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5335 - val_loss: 0.5085\n",
      "Epoch 66/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5326 - val_loss: 0.5076\n",
      "Epoch 67/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5318 - val_loss: 0.5072\n",
      "Epoch 68/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5311 - val_loss: 0.5068\n",
      "Epoch 69/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5304 - val_loss: 0.5063\n",
      "Epoch 70/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5297 - val_loss: 0.5056\n",
      "Epoch 71/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5292 - val_loss: 0.5053\n",
      "Epoch 72/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5287 - val_loss: 0.5050\n",
      "Epoch 73/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5283 - val_loss: 0.5047\n",
      "Epoch 74/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5278 - val_loss: 0.5044\n",
      "Epoch 75/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5274 - val_loss: 0.5043\n",
      "Epoch 76/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5271 - val_loss: 0.5039\n",
      "Epoch 77/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5266 - val_loss: 0.5036\n",
      "Epoch 78/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5264 - val_loss: 0.5036\n",
      "Epoch 79/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5261 - val_loss: 0.5032\n",
      "Epoch 80/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5257 - val_loss: 0.5032\n",
      "Epoch 81/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5256 - val_loss: 0.5031\n",
      "Epoch 82/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5254 - val_loss: 0.5033\n",
      "Epoch 83/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5251 - val_loss: 0.5029\n",
      "Epoch 84/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5250 - val_loss: 0.5026\n",
      "Epoch 85/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5249 - val_loss: 0.5029\n",
      "Epoch 86/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5246 - val_loss: 0.5027\n",
      "Epoch 87/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5245 - val_loss: 0.5029\n",
      "Epoch 88/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5243 - val_loss: 0.5029\n",
      "Epoch 89/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5242 - val_loss: 0.5027\n",
      "Epoch 90/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5241 - val_loss: 0.5028\n",
      "Epoch 91/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5240 - val_loss: 0.5030\n",
      "Epoch 92/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5239 - val_loss: 0.5025\n",
      "Epoch 93/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5238 - val_loss: 0.5024\n",
      "Epoch 94/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5238 - val_loss: 0.5026\n",
      "Epoch 95/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5237 - val_loss: 0.5027\n",
      "Epoch 96/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5235 - val_loss: 0.5024\n",
      "Epoch 97/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5235 - val_loss: 0.5028\n",
      "Epoch 98/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5234 - val_loss: 0.5027\n",
      "Epoch 99/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5233 - val_loss: 0.5027\n",
      "Epoch 100/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5234 - val_loss: 0.5026\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.1068 - val_loss: 4.5649\n",
      "Epoch 2/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.2130 - val_loss: 3.7565\n",
      "Epoch 3/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5034 - val_loss: 3.1114\n",
      "Epoch 4/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9265 - val_loss: 2.5936\n",
      "Epoch 5/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4531 - val_loss: 2.1621\n",
      "Epoch 6/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0616 - val_loss: 1.8115\n",
      "Epoch 7/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7374 - val_loss: 1.5206\n",
      "Epoch 8/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4688 - val_loss: 1.2821\n",
      "Epoch 9/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2478 - val_loss: 1.0869\n",
      "Epoch 10/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0679 - val_loss: 0.9313\n",
      "Epoch 11/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9239 - val_loss: 0.8065\n",
      "Epoch 12/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8110 - val_loss: 0.7122\n",
      "Epoch 13/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7243 - val_loss: 0.6407\n",
      "Epoch 14/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6595 - val_loss: 0.5893\n",
      "Epoch 15/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6132 - val_loss: 0.5530\n",
      "Epoch 16/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5809 - val_loss: 0.5300\n",
      "Epoch 17/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5597 - val_loss: 0.5157\n",
      "Epoch 18/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5467 - val_loss: 0.5078\n",
      "Epoch 19/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5390 - val_loss: 0.5034\n",
      "Epoch 20/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5348 - val_loss: 0.5019\n",
      "Epoch 21/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5328 - val_loss: 0.5008\n",
      "Epoch 22/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5318 - val_loss: 0.5004\n",
      "Epoch 23/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5315 - val_loss: 0.5014\n",
      "Epoch 24/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5313 - val_loss: 0.5014\n",
      "Epoch 25/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5311 - val_loss: 0.5017\n",
      "Epoch 26/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5014\n",
      "Epoch 27/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5017\n",
      "Epoch 28/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5311 - val_loss: 0.5014\n",
      "Epoch 29/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5019\n",
      "Epoch 30/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5016\n",
      "Epoch 31/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5016\n",
      "Epoch 32/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5013\n",
      "Epoch 33/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5017\n",
      "Epoch 34/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5012\n",
      "Epoch 35/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5021\n",
      "Epoch 36/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5022\n",
      "Epoch 37/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5013\n",
      "Epoch 38/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5020\n",
      "Epoch 39/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5020\n",
      "Epoch 40/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5308 - val_loss: 0.5017\n",
      "Epoch 41/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5307 - val_loss: 0.5016\n",
      "Epoch 42/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5023\n",
      "Epoch 43/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5026\n",
      "Epoch 44/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5017\n",
      "Epoch 45/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5022\n",
      "Epoch 46/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5020\n",
      "Epoch 47/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5014\n",
      "Epoch 48/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5018\n",
      "Epoch 49/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5021\n",
      "Epoch 50/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5016\n",
      "Epoch 51/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5308 - val_loss: 0.5023\n",
      "Epoch 52/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5305 - val_loss: 0.5019\n",
      "Epoch 53/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5018\n",
      "Epoch 54/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5018\n",
      "Epoch 55/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5017\n",
      "Epoch 56/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5311 - val_loss: 0.5038\n",
      "Epoch 57/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5024\n",
      "Epoch 58/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5018\n",
      "Epoch 59/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5022\n",
      "Epoch 60/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5305 - val_loss: 0.5012\n",
      "Epoch 61/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5022\n",
      "Epoch 62/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5020\n",
      "Epoch 63/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5018\n",
      "Epoch 64/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5011\n",
      "Epoch 65/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5024\n",
      "Epoch 66/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5017\n",
      "Epoch 67/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5022\n",
      "Epoch 68/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5305 - val_loss: 0.5025\n",
      "Epoch 69/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5027\n",
      "Epoch 70/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5019\n",
      "Epoch 71/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5017\n",
      "Epoch 72/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5020\n",
      "Epoch 73/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5312 - val_loss: 0.5024\n",
      "Epoch 74/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5015\n",
      "Epoch 75/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5022\n",
      "Epoch 76/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5016\n",
      "Epoch 77/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5016\n",
      "Epoch 78/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5018\n",
      "Epoch 79/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5029\n",
      "Epoch 80/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5026\n",
      "Epoch 81/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5025\n",
      "Epoch 82/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5307 - val_loss: 0.5022\n",
      "Epoch 83/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5305 - val_loss: 0.5023\n",
      "Epoch 84/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5023\n",
      "Epoch 85/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5024\n",
      "Epoch 86/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5024\n",
      "Epoch 87/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5022\n",
      "Epoch 88/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5022\n",
      "Epoch 89/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5025\n",
      "Epoch 90/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5025\n",
      "Epoch 91/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5017\n",
      "Epoch 92/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5021\n",
      "Epoch 93/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5305 - val_loss: 0.5027\n",
      "Epoch 94/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5020\n",
      "Epoch 95/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5027\n",
      "Epoch 96/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5026\n",
      "Epoch 97/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5309 - val_loss: 0.5026\n",
      "Epoch 98/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5025\n",
      "Epoch 99/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5022\n",
      "Epoch 100/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5030\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.6758 - val_loss: 5.4691\n",
      "Epoch 2/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.6137 - val_loss: 4.4719\n",
      "Epoch 3/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8330 - val_loss: 3.7062\n",
      "Epoch 4/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2313 - val_loss: 3.1171\n",
      "Epoch 5/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.7491 - val_loss: 2.6366\n",
      "Epoch 6/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3496 - val_loss: 2.2359\n",
      "Epoch 7/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0130 - val_loss: 1.8963\n",
      "Epoch 8/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.7295 - val_loss: 1.6151\n",
      "Epoch 9/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4915 - val_loss: 1.3810\n",
      "Epoch 10/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2945 - val_loss: 1.1903\n",
      "Epoch 11/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1333 - val_loss: 1.0346\n",
      "Epoch 12/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0031 - val_loss: 0.9135\n",
      "Epoch 13/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8996 - val_loss: 0.8176\n",
      "Epoch 14/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8190 - val_loss: 0.7454\n",
      "Epoch 15/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7575 - val_loss: 0.6916\n",
      "Epoch 16/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7111 - val_loss: 0.6519\n",
      "Epoch 17/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6764 - val_loss: 0.6224\n",
      "Epoch 18/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6505 - val_loss: 0.6008\n",
      "Epoch 19/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6307 - val_loss: 0.5842\n",
      "Epoch 20/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6152 - val_loss: 0.5720\n",
      "Epoch 21/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6029 - val_loss: 0.5597\n",
      "Epoch 22/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5920 - val_loss: 0.5503\n",
      "Epoch 23/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5831 - val_loss: 0.5426\n",
      "Epoch 24/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5750 - val_loss: 0.5354\n",
      "Epoch 25/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5682 - val_loss: 0.5295\n",
      "Epoch 26/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5622 - val_loss: 0.5238\n",
      "Epoch 27/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5570 - val_loss: 0.5194\n",
      "Epoch 28/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5524 - val_loss: 0.5153\n",
      "Epoch 29/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5486 - val_loss: 0.5133\n",
      "Epoch 30/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5455 - val_loss: 0.5100\n",
      "Epoch 31/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5427 - val_loss: 0.5081\n",
      "Epoch 32/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5404 - val_loss: 0.5062\n",
      "Epoch 33/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5386 - val_loss: 0.5050\n",
      "Epoch 34/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5370 - val_loss: 0.5041\n",
      "Epoch 35/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5357 - val_loss: 0.5027\n",
      "Epoch 36/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5346 - val_loss: 0.5022\n",
      "Epoch 37/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5336 - val_loss: 0.5023\n",
      "Epoch 38/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5327 - val_loss: 0.5015\n",
      "Epoch 39/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5323 - val_loss: 0.5021\n",
      "Epoch 40/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5318 - val_loss: 0.5020\n",
      "Epoch 41/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5313 - val_loss: 0.5017\n",
      "Epoch 42/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5019\n",
      "Epoch 43/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5022\n",
      "Epoch 44/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5019\n",
      "Epoch 45/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5302 - val_loss: 0.5013\n",
      "Epoch 46/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5301 - val_loss: 0.5017\n",
      "Epoch 47/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5299 - val_loss: 0.5018\n",
      "Epoch 48/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5299 - val_loss: 0.5015\n",
      "Epoch 49/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5296 - val_loss: 0.5023\n",
      "Epoch 50/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5295 - val_loss: 0.5025\n",
      "Epoch 51/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5294 - val_loss: 0.5026\n",
      "Epoch 52/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5294 - val_loss: 0.5022\n",
      "Epoch 53/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5295 - val_loss: 0.5017\n",
      "Epoch 54/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5292 - val_loss: 0.5033\n",
      "Epoch 55/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5293 - val_loss: 0.5030\n",
      "Epoch 56/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5292 - val_loss: 0.5026\n",
      "Epoch 57/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5292 - val_loss: 0.5034\n",
      "Epoch 58/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5294 - val_loss: 0.5028\n",
      "Epoch 59/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5292 - val_loss: 0.5025\n",
      "Epoch 60/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5290 - val_loss: 0.5026\n",
      "Epoch 61/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5291 - val_loss: 0.5032\n",
      "Epoch 62/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5292 - val_loss: 0.5030\n",
      "Epoch 63/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5291 - val_loss: 0.5034\n",
      "Epoch 64/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5291 - val_loss: 0.5033\n",
      "Epoch 65/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5291 - val_loss: 0.5039\n",
      "Epoch 66/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5291 - val_loss: 0.5041\n",
      "Epoch 67/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5291 - val_loss: 0.5032\n",
      "Epoch 68/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5292 - val_loss: 0.5033\n",
      "Epoch 69/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5290 - val_loss: 0.5028\n",
      "Epoch 70/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5290 - val_loss: 0.5038\n",
      "Epoch 71/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5291 - val_loss: 0.5031\n",
      "Epoch 72/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5291 - val_loss: 0.5038\n",
      "Epoch 73/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5289 - val_loss: 0.5025\n",
      "Epoch 74/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5291 - val_loss: 0.5033\n",
      "Epoch 75/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5289 - val_loss: 0.5037\n",
      "Epoch 76/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5290 - val_loss: 0.5037\n",
      "Epoch 77/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5290 - val_loss: 0.5046\n",
      "Epoch 78/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5290 - val_loss: 0.5042\n",
      "Epoch 79/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5288 - val_loss: 0.5033\n",
      "Epoch 80/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5289 - val_loss: 0.5046\n",
      "Epoch 81/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5290 - val_loss: 0.5029\n",
      "Epoch 82/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5289 - val_loss: 0.5037\n",
      "Epoch 83/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5289 - val_loss: 0.5034\n",
      "Epoch 84/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5290 - val_loss: 0.5038\n",
      "Epoch 85/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5291 - val_loss: 0.5032\n",
      "Epoch 86/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5292 - val_loss: 0.5034\n",
      "Epoch 87/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5291 - val_loss: 0.5045\n",
      "Epoch 88/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5288 - val_loss: 0.5034\n",
      "Epoch 89/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5288 - val_loss: 0.5041\n",
      "Epoch 90/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5290 - val_loss: 0.5038\n",
      "Epoch 91/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5289 - val_loss: 0.5035\n",
      "Epoch 92/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5288 - val_loss: 0.5049\n",
      "Epoch 93/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5291 - val_loss: 0.5042\n",
      "Epoch 94/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5288 - val_loss: 0.5036\n",
      "Epoch 95/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5289 - val_loss: 0.5049\n",
      "Epoch 96/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5290 - val_loss: 0.5042\n",
      "Epoch 97/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5289 - val_loss: 0.5048\n",
      "Epoch 98/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5289 - val_loss: 0.5045\n",
      "Epoch 99/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5289 - val_loss: 0.5040\n",
      "Epoch 100/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5289 - val_loss: 0.5052\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.6663 - val_loss: 6.8117\n",
      "Epoch 2/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7263 - val_loss: 5.8055\n",
      "Epoch 3/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9561 - val_loss: 4.9774\n",
      "Epoch 4/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3200 - val_loss: 4.2940\n",
      "Epoch 5/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7962 - val_loss: 3.7344\n",
      "Epoch 6/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3644 - val_loss: 3.2717\n",
      "Epoch 7/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0089 - val_loss: 2.8884\n",
      "Epoch 8/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7186 - val_loss: 2.5729\n",
      "Epoch 9/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4808 - val_loss: 2.3124\n",
      "Epoch 10/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2872 - val_loss: 2.0966\n",
      "Epoch 11/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1307 - val_loss: 1.9165\n",
      "Epoch 12/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0056 - val_loss: 1.7651\n",
      "Epoch 13/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9065 - val_loss: 1.6377\n",
      "Epoch 14/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8297 - val_loss: 1.5325\n",
      "Epoch 15/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7709 - val_loss: 1.4402\n",
      "Epoch 16/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7269 - val_loss: 1.3654\n",
      "Epoch 17/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6944 - val_loss: 1.3005\n",
      "Epoch 18/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6699 - val_loss: 1.2529\n",
      "Epoch 19/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6513 - val_loss: 1.1918\n",
      "Epoch 20/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6367 - val_loss: 1.1470\n",
      "Epoch 21/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6250 - val_loss: 1.1067\n",
      "Epoch 22/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6153 - val_loss: 1.0693\n",
      "Epoch 23/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6067 - val_loss: 1.0307\n",
      "Epoch 24/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5990 - val_loss: 0.9932\n",
      "Epoch 25/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5917 - val_loss: 0.9607\n",
      "Epoch 26/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5857 - val_loss: 0.9274\n",
      "Epoch 27/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5799 - val_loss: 0.8973\n",
      "Epoch 28/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5747 - val_loss: 0.8688\n",
      "Epoch 29/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5699 - val_loss: 0.8406\n",
      "Epoch 30/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5654 - val_loss: 0.8158\n",
      "Epoch 31/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5617 - val_loss: 0.7921\n",
      "Epoch 32/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5582 - val_loss: 0.7693\n",
      "Epoch 33/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5547 - val_loss: 0.7472\n",
      "Epoch 34/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5519 - val_loss: 0.7254\n",
      "Epoch 35/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5488 - val_loss: 0.7054\n",
      "Epoch 36/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5462 - val_loss: 0.6873\n",
      "Epoch 37/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5439 - val_loss: 0.6691\n",
      "Epoch 38/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5416 - val_loss: 0.6544\n",
      "Epoch 39/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5397 - val_loss: 0.6402\n",
      "Epoch 40/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5378 - val_loss: 0.6262\n",
      "Epoch 41/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5360 - val_loss: 0.6118\n",
      "Epoch 42/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5346 - val_loss: 0.6006\n",
      "Epoch 43/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5332 - val_loss: 0.5888\n",
      "Epoch 44/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5319 - val_loss: 0.5788\n",
      "Epoch 45/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5306 - val_loss: 0.5699\n",
      "Epoch 46/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5298 - val_loss: 0.5616\n",
      "Epoch 47/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5286 - val_loss: 0.5533\n",
      "Epoch 48/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5280 - val_loss: 0.5475\n",
      "Epoch 49/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5271 - val_loss: 0.5427\n",
      "Epoch 50/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5263 - val_loss: 0.5351\n",
      "Epoch 51/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5255 - val_loss: 0.5293\n",
      "Epoch 52/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5252 - val_loss: 0.5252\n",
      "Epoch 53/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5248 - val_loss: 0.5218\n",
      "Epoch 54/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5247 - val_loss: 0.5189\n",
      "Epoch 55/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5241 - val_loss: 0.5170\n",
      "Epoch 56/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5239 - val_loss: 0.5138\n",
      "Epoch 57/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5236 - val_loss: 0.5124\n",
      "Epoch 58/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5237 - val_loss: 0.5105\n",
      "Epoch 59/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5233 - val_loss: 0.5097\n",
      "Epoch 60/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5233 - val_loss: 0.5073\n",
      "Epoch 61/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5232 - val_loss: 0.5078\n",
      "Epoch 62/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5230 - val_loss: 0.5055\n",
      "Epoch 63/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5230 - val_loss: 0.5054\n",
      "Epoch 64/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5229 - val_loss: 0.5049\n",
      "Epoch 65/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5229 - val_loss: 0.5057\n",
      "Epoch 66/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5231 - val_loss: 0.5044\n",
      "Epoch 67/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5228 - val_loss: 0.5050\n",
      "Epoch 68/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5232 - val_loss: 0.5048\n",
      "Epoch 69/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5230 - val_loss: 0.5051\n",
      "Epoch 70/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5230 - val_loss: 0.5045\n",
      "Epoch 71/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5229 - val_loss: 0.5045\n",
      "Epoch 72/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5230 - val_loss: 0.5043\n",
      "Epoch 73/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5230 - val_loss: 0.5042\n",
      "Epoch 74/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5230 - val_loss: 0.5040\n",
      "Epoch 75/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5229 - val_loss: 0.5042\n",
      "Epoch 76/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5230 - val_loss: 0.5039\n",
      "Epoch 77/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5230 - val_loss: 0.5044\n",
      "Epoch 78/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5230 - val_loss: 0.5048\n",
      "Epoch 79/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5228 - val_loss: 0.5038\n",
      "Epoch 80/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5229 - val_loss: 0.5040\n",
      "Epoch 81/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5230 - val_loss: 0.5030\n",
      "Epoch 82/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5229 - val_loss: 0.5041\n",
      "Epoch 83/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5227 - val_loss: 0.5032\n",
      "Epoch 84/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5228 - val_loss: 0.5039\n",
      "Epoch 85/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5228 - val_loss: 0.5043\n",
      "Epoch 86/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5229 - val_loss: 0.5053\n",
      "Epoch 87/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5228 - val_loss: 0.5046\n",
      "Epoch 88/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5228 - val_loss: 0.5037\n",
      "Epoch 89/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5230 - val_loss: 0.5038\n",
      "Epoch 90/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5229 - val_loss: 0.5046\n",
      "Epoch 91/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5229 - val_loss: 0.5045\n",
      "Epoch 92/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5229 - val_loss: 0.5045\n",
      "Epoch 93/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5229 - val_loss: 0.5045\n",
      "Epoch 94/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5229 - val_loss: 0.5042\n",
      "Epoch 95/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5229 - val_loss: 0.5038\n",
      "Epoch 96/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5227 - val_loss: 0.5041\n",
      "Epoch 97/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5230 - val_loss: 0.5044\n",
      "Epoch 98/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5230 - val_loss: 0.5038\n",
      "Epoch 99/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5228 - val_loss: 0.5041\n",
      "Epoch 100/100\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5230 - val_loss: 0.5038\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:490: FitFailedWarning: \n",
      "24 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "    ~~~~~~~~~^\n",
      "        X=X,\n",
      "        ^^^^\n",
      "    ...<3 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "  File \"C:\\Users\\evacl\\AppData\\Local\\Temp\\ipykernel_9220\\545829813.py\", line 5, in build_model\n",
      "    model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
      "              ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 101, in __init__\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Received an invalid value for `units`, expected a positive integer. Received: units=44\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "    ~~~~~~~~~^\n",
      "        X=X,\n",
      "        ^^^^\n",
      "    ...<3 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "  File \"C:\\Users\\evacl\\AppData\\Local\\Temp\\ipykernel_9220\\545829813.py\", line 5, in build_model\n",
      "    model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
      "              ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 101, in __init__\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Received an invalid value for `units`, expected a positive integer. Received: units=13\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "    ~~~~~~~~~^\n",
      "        X=X,\n",
      "        ^^^^\n",
      "    ...<3 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "  File \"C:\\Users\\evacl\\AppData\\Local\\Temp\\ipykernel_9220\\545829813.py\", line 5, in build_model\n",
      "    model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
      "              ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 101, in __init__\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Received an invalid value for `units`, expected a positive integer. Received: units=6\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "    ~~~~~~~~~^\n",
      "        X=X,\n",
      "        ^^^^\n",
      "    ...<3 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "  File \"C:\\Users\\evacl\\AppData\\Local\\Temp\\ipykernel_9220\\545829813.py\", line 5, in build_model\n",
      "    model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
      "              ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 101, in __init__\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Received an invalid value for `units`, expected a positive integer. Received: units=42\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "    ~~~~~~~~~^\n",
      "        X=X,\n",
      "        ^^^^\n",
      "    ...<3 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "  File \"C:\\Users\\evacl\\AppData\\Local\\Temp\\ipykernel_9220\\545829813.py\", line 5, in build_model\n",
      "    model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
      "              ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 101, in __init__\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Received an invalid value for `units`, expected a positive integer. Received: units=41\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "    ~~~~~~~~~^\n",
      "        X=X,\n",
      "        ^^^^\n",
      "    ...<3 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "  File \"C:\\Users\\evacl\\AppData\\Local\\Temp\\ipykernel_9220\\545829813.py\", line 5, in build_model\n",
      "    model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
      "              ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 101, in __init__\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Received an invalid value for `units`, expected a positive integer. Received: units=70\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "    ~~~~~~~~~^\n",
      "        X=X,\n",
      "        ^^^^\n",
      "    ...<3 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "  File \"C:\\Users\\evacl\\AppData\\Local\\Temp\\ipykernel_9220\\545829813.py\", line 5, in build_model\n",
      "    model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
      "              ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 101, in __init__\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Received an invalid value for `units`, expected a positive integer. Received: units=12\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "    ~~~~~~~~~^\n",
      "        X=X,\n",
      "        ^^^^\n",
      "    ...<3 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "  File \"C:\\Users\\evacl\\AppData\\Local\\Temp\\ipykernel_9220\\545829813.py\", line 5, in build_model\n",
      "    model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
      "              ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 101, in __init__\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Received an invalid value for `units`, expected a positive integer. Received: units=64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1137: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.60846128        nan 0.60833046\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Proj\\homl-deep-learning-ensemble-unsupervised\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.3977 - val_loss: 6.6043\n",
      "Epoch 2/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.4416 - val_loss: 5.7236\n",
      "Epoch 3/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.6625 - val_loss: 4.9844\n",
      "Epoch 4/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.0262 - val_loss: 4.3871\n",
      "Epoch 5/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.5037 - val_loss: 3.8883\n",
      "Epoch 6/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.0699 - val_loss: 3.4716\n",
      "Epoch 7/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7047 - val_loss: 3.1156\n",
      "Epoch 8/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.3949 - val_loss: 2.8068\n",
      "Epoch 9/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1277 - val_loss: 2.5370\n",
      "Epoch 10/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8941 - val_loss: 2.3119\n",
      "Epoch 11/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6882 - val_loss: 2.0831\n",
      "Epoch 12/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5057 - val_loss: 1.8917\n",
      "Epoch 13/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3453 - val_loss: 1.7216\n",
      "Epoch 14/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2043 - val_loss: 1.5690\n",
      "Epoch 15/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0818 - val_loss: 1.4337\n",
      "Epoch 16/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9772 - val_loss: 1.3178\n",
      "Epoch 17/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8894 - val_loss: 1.2191\n",
      "Epoch 18/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8167 - val_loss: 1.1342\n",
      "Epoch 19/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7575 - val_loss: 1.0618\n",
      "Epoch 20/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7107 - val_loss: 1.0018\n",
      "Epoch 21/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6745 - val_loss: 0.9527\n",
      "Epoch 22/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6479 - val_loss: 0.9116\n",
      "Epoch 23/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6282 - val_loss: 0.8792\n",
      "Epoch 24/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6143 - val_loss: 0.8502\n",
      "Epoch 25/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6041 - val_loss: 0.8251\n",
      "Epoch 26/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5963 - val_loss: 0.8003\n",
      "Epoch 27/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5903 - val_loss: 0.7797\n",
      "Epoch 28/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5854 - val_loss: 0.7595\n",
      "Epoch 29/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5807 - val_loss: 0.7407\n",
      "Epoch 30/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5766 - val_loss: 0.7227\n",
      "Epoch 31/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5727 - val_loss: 0.7046\n",
      "Epoch 32/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5689 - val_loss: 0.6873\n",
      "Epoch 33/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5653 - val_loss: 0.6716\n",
      "Epoch 34/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5621 - val_loss: 0.6569\n",
      "Epoch 35/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5591 - val_loss: 0.6436\n",
      "Epoch 36/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5563 - val_loss: 0.6310\n",
      "Epoch 37/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5538 - val_loss: 0.6186\n",
      "Epoch 38/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5513 - val_loss: 0.6075\n",
      "Epoch 39/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5491 - val_loss: 0.5968\n",
      "Epoch 40/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5470 - val_loss: 0.5869\n",
      "Epoch 41/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5451 - val_loss: 0.5775\n",
      "Epoch 42/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5433 - val_loss: 0.5692\n",
      "Epoch 43/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5417 - val_loss: 0.5642\n",
      "Epoch 44/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5402 - val_loss: 0.5534\n",
      "Epoch 45/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5387 - val_loss: 0.5474\n",
      "Epoch 46/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5375 - val_loss: 0.5422\n",
      "Epoch 47/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5364 - val_loss: 0.5370\n",
      "Epoch 48/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5353 - val_loss: 0.5327\n",
      "Epoch 49/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5345 - val_loss: 0.5282\n",
      "Epoch 50/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5336 - val_loss: 0.5246\n",
      "Epoch 51/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5329 - val_loss: 0.5213\n",
      "Epoch 52/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5322 - val_loss: 0.5183\n",
      "Epoch 53/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5317 - val_loss: 0.5158\n",
      "Epoch 54/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5312 - val_loss: 0.5143\n",
      "Epoch 55/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5308 - val_loss: 0.5125\n",
      "Epoch 56/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5304 - val_loss: 0.5111\n",
      "Epoch 57/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5300 - val_loss: 0.5103\n",
      "Epoch 58/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5298 - val_loss: 0.5090\n",
      "Epoch 59/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5296 - val_loss: 0.5086\n",
      "Epoch 60/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5294 - val_loss: 0.5073\n",
      "Epoch 61/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5292 - val_loss: 0.5069\n",
      "Epoch 62/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5290 - val_loss: 0.5070\n",
      "Epoch 63/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5289 - val_loss: 0.5068\n",
      "Epoch 64/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5287 - val_loss: 0.5063\n",
      "Epoch 65/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5286 - val_loss: 0.5056\n",
      "Epoch 66/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5286 - val_loss: 0.5058\n",
      "Epoch 67/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5285 - val_loss: 0.5058\n",
      "Epoch 68/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5284 - val_loss: 0.5057\n",
      "Epoch 69/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5284 - val_loss: 0.5056\n",
      "Epoch 70/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5283 - val_loss: 0.5055\n",
      "Epoch 71/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5281 - val_loss: 0.5055\n",
      "Epoch 72/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5282 - val_loss: 0.5053\n",
      "Epoch 73/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5281 - val_loss: 0.5054\n",
      "Epoch 74/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5280 - val_loss: 0.5051\n",
      "Epoch 75/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5279 - val_loss: 0.5053\n",
      "Epoch 76/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5280 - val_loss: 0.5047\n",
      "Epoch 77/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5279 - val_loss: 0.5050\n",
      "Epoch 78/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.5279 - val_loss: 0.5049\n",
      "Epoch 79/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5278 - val_loss: 0.5048\n",
      "Epoch 80/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5278 - val_loss: 0.5046\n",
      "Epoch 81/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5278 - val_loss: 0.5047\n",
      "Epoch 82/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5278 - val_loss: 0.5045\n",
      "Epoch 83/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5278 - val_loss: 0.5045\n",
      "Epoch 84/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5278 - val_loss: 0.5047\n",
      "Epoch 85/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5277 - val_loss: 0.5041\n",
      "Epoch 86/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5277 - val_loss: 0.5039\n",
      "Epoch 87/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5277 - val_loss: 0.5041\n",
      "Epoch 88/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5276 - val_loss: 0.5041\n",
      "Epoch 89/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5276 - val_loss: 0.5038\n",
      "Epoch 90/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5276 - val_loss: 0.5041\n",
      "Epoch 91/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5276 - val_loss: 0.5039\n",
      "Epoch 92/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5276 - val_loss: 0.5040\n",
      "Epoch 93/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5275 - val_loss: 0.5038\n",
      "Epoch 94/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5275 - val_loss: 0.5041\n",
      "Epoch 95/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5276 - val_loss: 0.5040\n",
      "Epoch 96/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5276 - val_loss: 0.5039\n",
      "Epoch 97/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5275 - val_loss: 0.5040\n",
      "Epoch 98/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5275 - val_loss: 0.5042\n",
      "Epoch 99/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5275 - val_loss: 0.5038\n",
      "Epoch 100/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5275 - val_loss: 0.5037\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(build_fn=&lt;function build_model at 0x0000015A953C94E0&gt;),\n",
       "                   param_distributions={&#x27;model__learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000015A92F02450&gt;,\n",
       "                                        &#x27;model__n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;model__n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>An object of that type is instantiated for each grid point.<br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">KerasRegresso...se\n",
       "\tepochs=1\n",
       ")</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_distributions',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=param_distributions,-dict%20or%20list%20of%20dicts\">\n",
       "            param_distributions\n",
       "            <span class=\"param-doc-description\">param_distributions: dict or list of dicts<br><br>Dictionary with parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions).<br>If a list is given, it is sampled uniformly.<br>If a list of dicts is given, first a dict is sampled uniformly, and<br>then a parameter is sampled using that dict as above.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;model__learning_rate&#x27;: &lt;scipy.stats....0015A92F02450&gt;, &#x27;model__n_hidden&#x27;: [0, 1, ...], &#x27;model__n_neurons&#x27;: array([ 1,  2..., 97, 98, 99])}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=n_iter,-int%2C%20default%3D10\">\n",
       "            n_iter\n",
       "            <span class=\"param-doc-description\">n_iter: int, default=10<br><br>Number of parameter settings that are sampled. n_iter trades<br>off runtime vs quality of the solution.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.<br><br>If None, the estimator's score method is used.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given the ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``RandomizedSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Pseudo random number generator state used for random uniform sampling<br>from lists of possible values instead of scipy.stats distributions.<br>Pass an int for reproducible output across multiple<br>function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: KerasRegressor</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>KerasRegressor(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function build_model at 0x0000015A953C94E0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tmodel__learning_rate=0.0003228398337457386\n",
       "\tmodel__n_hidden=0\n",
       "\tmodel__n_neurons=77\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KerasRegressor</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('model',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">model</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('build_fn',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">build_fn</td>\n",
       "            <td class=\"value\">&lt;function bui...0015A953C94E0&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('optimizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">optimizer</td>\n",
       "            <td class=\"value\">&#x27;rmsprop&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">loss</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metrics',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metrics</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('batch_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">batch_size</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_batch_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_batch_size</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_split</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shuffle',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shuffle</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('run_eagerly',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">run_eagerly</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('epochs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">epochs</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('model__learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">model__learning_rate</td>\n",
       "            <td class=\"value\">np.float64(0....8398337457386)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('model__n_hidden',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">model__n_hidden</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('model__n_neurons',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">model__n_neurons</td>\n",
       "            <td class=\"value\">np.int64(77)</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(build_fn=<function build_model at 0x0000015A953C94E0>),\n",
       "                   param_distributions={'model__learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000015A92F02450>,\n",
       "                                        'model__n_hidden': [0, 1, 2, 3],\n",
       "                                        'model__n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# por estar usando o scikeras, os parâmetros do modelo precisam ser prefixados com model__.\n",
    "params_ = {\n",
    "    'model__n_hidden': [0, 1, 2, 3],\n",
    "    'model__n_neurons': np.arange(1, 100),\n",
    "    'model__learning_rate': reciprocal(1e-4, 1e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, params_, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "720b3764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__learning_rate': np.float64(0.0003228398337457386),\n",
       " 'model__n_hidden': 0,\n",
       " 'model__n_neurons': np.int64(77)}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3697f86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6084612787965359)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57dfe2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c017ffe",
   "metadata": {},
   "source": [
    "Algumas bibliotecas que podemos utilizar para otimizar os hiperparâmetros:\n",
    "\n",
    "- Hyperopt:\n",
    "    Busca otimizar todos os tipos de espaço de pesquisa complexos (valores reais como taxa de aprendizado, valores discretos como número de camadas)\n",
    "- Hyperas, kopt ou Talos:\n",
    "    Úteis para otimizar hiperparâmetros para modelos Keras\n",
    "- Keras Tuner:\n",
    "    Biblioteca de otimização de hiperparâmetros do Google fácil de usar para modelos Keras, com serviço hospedado para visualização e análise.\n",
    "- Scikit-Optimize (skopt):\n",
    "    Biblioteca de otimização de uso geral, a classe _BayesSearchCV()_ usa uma otimização bayesiana com interface semelhante ao _GridSearchCV()_\n",
    "- Spearmint:\n",
    "    Otimização Bayesiana\n",
    "- Hyperband:\n",
    "    Biblioteca de ajuste rápido de hiperparâmetros\n",
    "- SKlearn-Deap:\n",
    "    Biblioteca de otimização baseada em algoritmos evolutivos com uma interface semelhante ao _GridSearchCV()_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
